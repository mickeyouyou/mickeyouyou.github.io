<html>
<head>
	
	<!-- hexo-inject:begin --><!-- hexo-inject:end --><title>基于NLTK的自动驾驶词频分析</title>
	<meta name="keywords" content="fzb.me,冯宗宝,冯宗宝的blog" />

    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    
	   <link href="/css/main.css?v=4.3" rel="stylesheet" type="text/css" />
    
        <script src="/js/util.js"></script>
        <script>
            if(isMobile()) {
                loadjscssfile('../css/mobile.css', 'css');
            } else {
                loadjscssfile('../css/desktop.css', 'css');
            }
        </script> 
    

    <link rel="alternate" type="application/atom+xml" href="/atom.xml" title="Atom feed">

    
	   <link rel="shortcut icon" type="image/x-icon" href="/rocket_128px_1215034_easyicon.net.ico?v=4.3"/><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    

</head>

<body>


<!-- hexo-inject:begin --><!-- hexo-inject:end --><h2 class="title">基于NLTK的自动驾驶词频分析</h2>
<!---
<div style="text-align:center;margin-top: -10px;">
<div class="article-category">
发表于2017年11月21日




 </div>
--->
</div>

<ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#描述"><span class="toc-text"><a href="#&#x63CF;&#x8FF0;" class="headerlink" title="&#x63CF;&#x8FF0;"></a>&#x63CF;&#x8FF0;</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#思路"><span class="toc-text"><a href="#&#x601D;&#x8DEF;" class="headerlink" title="&#x601D;&#x8DEF;"></a>&#x601D;&#x8DEF;</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#单篇文章实践"><span class="toc-text"><a href="#&#x5355;&#x7BC7;&#x6587;&#x7AE0;&#x5B9E;&#x8DF5;" class="headerlink" title="&#x5355;&#x7BC7;&#x6587;&#x7AE0;&#x5B9E;&#x8DF5;"></a>&#x5355;&#x7BC7;&#x6587;&#x7AE0;&#x5B9E;&#x8DF5;</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#文章内容"><span class="toc-text"><a href="#&#x6587;&#x7AE0;&#x5185;&#x5BB9;" class="headerlink" title="&#x6587;&#x7AE0;&#x5185;&#x5BB9;"></a>&#x6587;&#x7AE0;&#x5185;&#x5BB9;</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#链表化"><span class="toc-text"><a href="#&#x94FE;&#x8868;&#x5316;" class="headerlink" title="&#x94FE;&#x8868;&#x5316;"></a>&#x94FE;&#x8868;&#x5316;</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#词频分析"><span class="toc-text"><a href="#&#x8BCD;&#x9891;&#x5206;&#x6790;" class="headerlink" title="&#x8BCD;&#x9891;&#x5206;&#x6790;"></a>&#x8BCD;&#x9891;&#x5206;&#x6790;</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#移除噪声"><span class="toc-text"><a href="#&#x79FB;&#x9664;&#x566A;&#x58F0;" class="headerlink" title="&#x79FB;&#x9664;&#x566A;&#x58F0;"></a>&#x79FB;&#x9664;&#x566A;&#x58F0;</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#增加抓取部分"><span class="toc-text"><a href="#&#x589E;&#x52A0;&#x6293;&#x53D6;&#x90E8;&#x5206;" class="headerlink" title="&#x589E;&#x52A0;&#x6293;&#x53D6;&#x90E8;&#x5206;"></a>&#x589E;&#x52A0;&#x6293;&#x53D6;&#x90E8;&#x5206;</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#确定数据源"><span class="toc-text"><a href="#&#x786E;&#x5B9A;&#x6570;&#x636E;&#x6E90;" class="headerlink" title="&#x786E;&#x5B9A;&#x6570;&#x636E;&#x6E90;"></a>&#x786E;&#x5B9A;&#x6570;&#x636E;&#x6E90;</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#HTML内容处理"><span class="toc-text"><a href="#HTML&#x5185;&#x5BB9;&#x5904;&#x7406;" class="headerlink" title="HTML&#x5185;&#x5BB9;&#x5904;&#x7406;"></a>HTML&#x5185;&#x5BB9;&#x5904;&#x7406;</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Questions"><span class="toc-text"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#参考"><span class="toc-text"><a href="#&#x53C2;&#x8003;" class="headerlink" title="&#x53C2;&#x8003;"></a>&#x53C2;&#x8003;</span></a></li></ol>
<p>因工作关系，掌握某个领域（比如自动驾驶领域）的英文词汇，尤其高频词汇，对分析整个行业讨论的重点有所知晓的同时，对语言沟通也很重要。</p>
<h2 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h2><ol>
<li>抓取100篇和自动驾驶有关的文章、新闻到论文；（BeautifulSoup + nltk）</li>
<li>找出与自动驾驶有关的高频重点词汇；（需要规则匹配）</li>
<li>自动给出释义和用法，最终做成一个和自动驾驶相关的高频词库(存储)</li>
</ol>
<h2 id="思路"><a href="#思路" class="headerlink" title="思路"></a>思路</h2><p>之前对自然语言处理有过一定了解，对于最基本的处理方式有一些了解。本次正是一个实际操练的过程。</p>
<p>NLTK，Natural Language Toolkit，自然语言处理工具包，在NLP领域中，最常使用的一个Python库。</p>
<p>主要过程:</p>
<ul>
<li>文本处理；<ul>
<li>移除噪声</li>
<li>词汇规范化</li>
<li>对象标准化    </li>
</ul>
</li>
<li>词频分析</li>
</ul>
<p><img src="https://www.jiqizhixin.com/data/upload/ueditor/20170216/58a5485e67795.png" alt=""></p>
<p align="center">文本处理流程</p>

<p>以下，先从一段文本的处理，得到词频获取的一般流程，然后从web数据源抓取HTML内容的自动驾驶相关新闻数据，做进一步处理。</p>
<h2 id="单篇文章实践"><a href="#单篇文章实践" class="headerlink" title="单篇文章实践"></a>单篇文章实践</h2><p>要完成批量的过程，必须的一个过程是批量处理。以下，从单篇文档的角度，讲述分段分句，分词的处理过程。</p>
<h3 id="文章内容"><a href="#文章内容" class="headerlink" title="文章内容"></a>文章内容</h3><p>Toyota Will Test Their AI-Powered Driverless Cars in 2020：<br><a href="https://futurism.com/toyota-will-test-their-ai-powered-driverless-cars-in-2020/" target="_blank" rel="noopener">https://futurism.com/toyota-will-test-their-ai-powered-driverless-cars-in-2020/</a></p>
<p>可以基于HTML内容，再做去HTML标签的做法，得到真正关心的内容。<br>前期先将文章内容拷贝制作成为一个单独的数据文件。</p>
<h3 id="链表化"><a href="#链表化" class="headerlink" title="链表化"></a>链表化</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fdist2 = tokenizer.tokenize(raw)</span><br></pre></td></tr></table></figure>
<h3 id="词频分析"><a href="#词频分析" class="headerlink" title="词频分析"></a>词频分析</h3><figure class="highlight python"><table><tr><td class="code"><pre><span class="line">fdist2 = tokenizer.tokenize(raw)</span><br><span class="line">fdist2.plot(<span class="number">50</span>, cumulative=<span class="keyword">True</span>);</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>fdist2.items()</span><br><span class="line">[(<span class="string">'all'</span>, <span class="number">1</span>), (<span class="string">'concept'</span>, <span class="number">1</span>), (<span class="string">'Powered'</span>, <span class="number">1</span>), (<span class="string">'expects'</span>, <span class="number">1</span>), (<span class="string">'month'</span>, <span class="number">1</span>), (<span class="string">'Okabe'</span>, <span class="number">1</span>), (<span class="string">'driverless'</span>, <span class="number">1</span>), (<span class="string">'planning'</span>, <span class="number">2</span>), (<span class="string">'through'</span>, <span class="number">1</span>), (<span class="string">'emotions'</span>, <span class="number">1</span>), (<span class="string">'Test'</span>, <span class="number">1</span>), (<span class="string">'its'</span>, <span class="number">1</span>), (<span class="string">'boundaries'</span>, <span class="number">1</span>), (<span class="string">'supposedly'</span>, <span class="number">1</span>), (<span class="string">'title'</span>, <span class="number">1</span>), (<span class="string">'drive'</span>, <span class="number">1</span>), (<span class="string">'better'</span>, <span class="number">1</span>), (<span class="string">'to'</span>, <span class="number">12</span>), (<span class="string">'only'</span>, <span class="number">1</span>), (<span class="string">'going'</span>, <span class="number">1</span>), (<span class="string">'equipped'</span>, <span class="number">1</span>), (<span class="string">'has'</span>, <span class="number">1</span>), (<span class="string">'By'</span>, <span class="number">1</span>), (<span class="string">'meant'</span>, <span class="number">1</span>), (<span class="string">'division'</span>, <span class="number">1</span>), (<span class="string">'tests'</span>, <span class="number">1</span>), (<span class="string">'hit'</span>, <span class="number">1</span>), (<span class="string">'unveiling'</span>, <span class="number">1</span>), (<span class="string">'get'</span>, <span class="number">1</span>), (<span class="string">'assistant'</span>, <span class="number">1</span>), (<span class="string">'BRIEF'</span>, <span class="number">1</span>), (<span class="string">'know'</span>, <span class="number">1</span>), (<span class="string">'using'</span>, <span class="number">2</span>), (<span class="string">'now'</span>, <span class="number">1</span>), (<span class="string">'governments'</span>, <span class="number">1</span>), (<span class="string">'runs'</span>, <span class="number">2</span>), (<span class="string">'trucks'</span>, <span class="number">1</span>), (<span class="string">'bring'</span>, <span class="number">1</span>), (<span class="string">'manager'</span>, <span class="number">1</span>), (<span class="string">'drivers'</span>, <span class="number">1</span>), (<span class="string">'this'</span>, <span class="number">1</span>), (<span class="string">'habits'</span>, <span class="number">1</span>), (<span class="string">'t'</span>, <span class="number">2</span>), (<span class="string">'enhance'</span>, <span class="number">1</span>), (<span class="string">'works'</span>, <span class="number">1</span>), (<span class="string">'futuristic'</span>, <span class="number">1</span>), (<span class="string">'Tokyo'</span>, <span class="number">1</span>), (<span class="string">'Management'</span>, <span class="number">1</span>), (<span class="string">'isn\xe2'</span>, <span class="number">2</span>), (<span class="string">'intelligence'</span>, <span class="number">1</span>), (<span class="string">'testing'</span>, <span class="number">2</span>), (<span class="string">'are'</span>, <span class="number">2</span>), (<span class="string">'combining'</span>, <span class="number">1</span>), (<span class="string">'arm'</span>, <span class="number">1</span>), (<span class="string">'transport'</span>, <span class="number">1</span>), (<span class="string">'said'</span>, <span class="number">1</span>), (<span class="string">'preferences'</span>, <span class="number">1</span>), (<span class="string">'for'</span>, <span class="number">5</span>), (<span class="string">'Driverless'</span>, <span class="number">1</span>), (<span class="string">'artificial'</span>, <span class="number">1</span>), (<span class="string">'content'</span>, <span class="number">1</span>), (<span class="string">'capital'</span>, <span class="number">1</span>), (<span class="string">'new'</span>, <span class="number">1</span>), (<span class="string">'be'</span>, <span class="number">4</span>), (<span class="string">'we'</span>, <span class="number">1</span>), (<span class="string">'transportation'</span>, <span class="number">1</span>), (<span class="string">'business'</span>, <span class="number">1</span>), (<span class="string">'cars'</span>, <span class="number">4</span>), (<span class="string">'pushing'</span>, <span class="number">1</span>), (<span class="string">'notable'</span>, <span class="number">1</span>), (<span class="string">'however'</span>, <span class="number">1</span>), (<span class="string">'Yui'</span>, <span class="number">4</span>), (<span class="string">'EV'</span>, <span class="number">1</span>), (<span class="string">'by'</span>, <span class="number">2</span>), (<span class="string">'manufacturer'</span>, <span class="number">1</span>), (<span class="string">'on'</span>, <span class="number">1</span>), (<span class="string">'Concept'</span>, <span class="number">2</span>), (<span class="string">'of'</span>, <span class="number">6</span>), (<span class="string">'Image'</span>, <span class="number">2</span>), (<span class="string">'experience'</span>, <span class="number">1</span>), (<span class="string">'trial'</span>, <span class="number">2</span>), (<span class="string">'s'</span>, <span class="number">2</span>), (<span class="string">'games'</span>, <span class="number">1</span>), (<span class="string">'Makoto'</span>, <span class="number">1</span>), (<span class="string">'year'</span>, <span class="number">1</span>), (<span class="string">'billions'</span>, <span class="number">1</span>), (<span class="string">'Their'</span>, <span class="number">1</span>), (<span class="string">'learning'</span>, <span class="number">1</span>), (<span class="string">'roads'</span>, <span class="number">1</span>), (<span class="string">'your'</span>, <span class="number">1</span>), (<span class="string">'Sure'</span>, <span class="number">1</span>), (<span class="string">'Olympic'</span>, <span class="number">1</span>), (<span class="string">'powered'</span>, <span class="number">2</span>), (<span class="string">'spending'</span>, <span class="number">1</span>), (<span class="string">'Cars'</span>, <span class="number">1</span>), (<span class="string">'flying'</span>, <span class="number">1</span>), (<span class="string">'system'</span>, <span class="number">1</span>), (<span class="string">'start'</span>, <span class="number">1</span>), (<span class="string">'expand'</span>, <span class="number">1</span>), (<span class="string">'way'</span>, <span class="number">1</span>), (<span class="string">'vehicle'</span>, <span class="number">1</span>), (<span class="string">'Toyota\xe2'</span>, <span class="number">1</span>), (<span class="string">'speaking'</span>, <span class="number">1</span>), (<span class="string">'wants'</span>, <span class="number">2</span>), (<span class="string">'that'</span>, <span class="number">2</span>), (<span class="string">'company'</span>, <span class="number">1</span>), (<span class="string">'Credit'</span>, <span class="number">1</span>), (<span class="string">'line'</span>, <span class="number">1</span>), (<span class="string">'general'</span>, <span class="number">1</span>), (<span class="string">'with'</span>, <span class="number">4</span>), (<span class="string">'builds'</span>, <span class="number">1</span>), (<span class="string">'these'</span>, <span class="number">3</span>), (<span class="string">'car'</span>, <span class="number">2</span>), (<span class="string">'will'</span>, <span class="number">2</span>), (<span class="string">'future'</span>, <span class="number">1</span>), (<span class="string">'2020'</span>, <span class="number">5</span>), (<span class="string">'venture'</span>, <span class="number">1</span>), (<span class="string">'carmakers'</span>, <span class="number">1</span>), (<span class="string">'making'</span>, <span class="number">1</span>), (<span class="string">'autonomous'</span>, <span class="number">3</span>), (<span class="string">'called'</span>, <span class="number">2</span>), (<span class="string">'affection'</span>, <span class="number">1</span>), (<span class="string">'and'</span>, <span class="number">4</span>), (<span class="string">'promises'</span>, <span class="number">1</span>), (<span class="string">'later'</span>, <span class="number">1</span>), (<span class="string">'want'</span>, <span class="number">1</span>), (<span class="string">'Cartivator'</span>, <span class="number">1</span>), (<span class="string">'is'</span>, <span class="number">4</span>), (<span class="string">'partnership'</span>, <span class="number">1</span>), (<span class="string">'them'</span>, <span class="number">1</span>), (<span class="string">'deep'</span>, <span class="number">1</span>), (<span class="string">'an'</span>, <span class="number">2</span>), (<span class="string">'as'</span>, <span class="number">1</span>), (<span class="string">'chat'</span>, <span class="number">1</span>), (<span class="string">'in'</span>, <span class="number">7</span>), (<span class="string">'seem'</span>, <span class="number">1</span>), (<span class="string">'technology'</span>, <span class="number">1</span>), (<span class="string">'their'</span>, <span class="number">6</span>), (<span class="string">'Reuters'</span>, <span class="number">1</span>), (<span class="string">'again'</span>, <span class="number">1</span>), (<span class="string">'different'</span>, <span class="number">1</span>), (<span class="string">'credit'</span>, <span class="number">1</span>), (<span class="string">'hydrogen'</span>, <span class="number">1</span>), (<span class="string">'self'</span>, <span class="number">1</span>), (<span class="string">'After'</span>, <span class="number">1</span>), (<span class="string">'able'</span>, <span class="number">1</span>), (<span class="string">'virtual'</span>, <span class="number">1</span>), (<span class="string">'also'</span>, <span class="number">1</span>), (<span class="string">'which'</span>, <span class="number">1</span>), (<span class="string">'test'</span>, <span class="number">1</span>), (<span class="string">'development'</span>, <span class="number">2</span>), (<span class="string">'product'</span>, <span class="number">1</span>), (<span class="string">'Resource'</span>, <span class="number">1</span>), (<span class="string">'AI'</span>, <span class="number">7</span>), (<span class="string">'object'</span>, <span class="number">1</span>), (<span class="string">'Toyota'</span>, <span class="number">10</span>), (<span class="string">'Will'</span>, <span class="number">1</span>), (<span class="string">'paving'</span>, <span class="number">1</span>), (<span class="string">'waves'</span>, <span class="number">1</span>), (<span class="string">'The'</span>, <span class="number">3</span>), (<span class="string">'the'</span>, <span class="number">10</span>), (<span class="string">'carmaker'</span>, <span class="number">1</span>), (<span class="string">'Yui\xe2'</span>, <span class="number">1</span>), (<span class="string">'a'</span>, <span class="number">4</span>), (<span class="string">'\xe2'</span>, <span class="number">4</span>), (<span class="string">'driving'</span>, <span class="number">3</span>), (<span class="string">'i'</span>, <span class="number">2</span>), (<span class="string">'vehicles'</span>, <span class="number">3</span>), (<span class="string">'Japanese'</span>, <span class="number">2</span>), (<span class="string">'time'</span>, <span class="number">1</span>), (<span class="string">'model'</span>, <span class="number">1</span>), (<span class="string">'looking'</span>, <span class="number">1</span>), (<span class="string">'make'</span>, <span class="number">1</span>), (<span class="string">'typical'</span>, <span class="number">1</span>)]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>fdist2.max()</span><br><span class="line"><span class="string">'to'</span></span><br></pre></td></tr></table></figure>
<p>词频排名前15分析：<br><img src="http://7tsys1.com1.z0.glb.clouddn.com/figure_2_counts.png" width="79%"></p>
<p>累计词频排名前15如下：<br><img src="http://7tsys1.com1.z0.glb.clouddn.com/figure_1.png" alt="" width="79%"></p>
<h3 id="移除噪声"><a href="#移除噪声" class="headerlink" title="移除噪声"></a>移除噪声</h3><p>何为噪声？<br>任何与数据上下文和最终输出无关的文本都可被判作噪声。</p>
<p>问题：排名在前的介词，连接词等，这些词被称为语言停止词（stopword，语言中常用的词汇：系动词is，am，定冠词the，介词of，in），均不会成为我们关心的内容，需要过滤掉。</p>
<p>解决方案：去除停止次</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> RegexpTokenizer </span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</span><br><span class="line"><span class="keyword">from</span> nltk.book <span class="keyword">import</span> * </span><br><span class="line"></span><br><span class="line">f = open(<span class="string">'news1'</span>)</span><br><span class="line">raw = f.read()</span><br><span class="line">tokenizer = RegexpTokenizer(<span class="string">r'\w+'</span>)</span><br><span class="line">fdist2 = tokenizer.tokenize(raw.decode(<span class="string">'utf-8'</span>))</span><br><span class="line"></span><br><span class="line">filtered = [word <span class="keyword">for</span> word <span class="keyword">in</span> fdist2 <span class="keyword">if</span>(word <span class="keyword">not</span> <span class="keyword">in</span> stopwords.words(<span class="string">'english'</span>))]</span><br><span class="line">fd = FreqDist(filtered)</span><br><span class="line">fd.plot(<span class="number">20</span>, cumulative=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure>
<p>去掉停止词之后的效果，已经明显的吐出了其中要点词：<br><img src="http://7tsys1.com1.z0.glb.clouddn.com/figure_stopwords.png" width="79%"></p>
<p>news2:<br><img src="http://7tsys1.com1.z0.glb.clouddn.com/figure_stopwords_for_news2.png" width="79%" alt=""><br>news3:<br><img src="http://7tsys1.com1.z0.glb.clouddn.com/figure_stopwords_for_news3.png" width="79%" alt=""></p>
<p>还存在的问题：</p>
<ul>
<li>‘Las Vegas’这样的连词被拆分为了两个词</li>
<li>‘The’ 这样的次还存在，在三个数据中，均有体现。</li>
</ul>
<p><img src="http://7tsys1.com1.z0.glb.clouddn.com/figure_stopwords_lower_for_news3.png" width="79%" alt=""></p>
<p>TODO 解决办法：</p>
<ul>
<li>不区分大小写</li>
<li>联合搭配</li>
</ul>
<p>要做自己的词频库，下一步就是将这些词，与对应的词组结合起来，是跟其使用情况结合。</p>
<p>到目前为止，方案已经可行。为了将该过程做成自动化的过程，以下是该部分的完整逻辑：</p>
<h2 id="增加抓取部分"><a href="#增加抓取部分" class="headerlink" title="增加抓取部分"></a>增加抓取部分</h2><h3 id="确定数据源"><a href="#确定数据源" class="headerlink" title="确定数据源"></a>确定数据源</h3><ul>
<li>Futurism: <a href="https://futurism.com/tag/autonomous-vehicles/" target="_blank" rel="noopener">https://futurism.com/tag/autonomous-vehicles/</a></li>
<li>卫报:<a href="https://www.theguardian.com/technology/self-driving-cars" target="_blank" rel="noopener">https://www.theguardian.com/technology/self-driving-cars</a></li>
<li>THEVERGE:<a href="https://www.theverge.com/autonomous-cars/archives" target="_blank" rel="noopener">https://www.theverge.com/autonomous-cars/archives</a></li>
<li>Fortune:<a href="http://fortune.com/tag/driverless-cars/" target="_blank" rel="noopener">http://fortune.com/tag/driverless-cars/</a></li>
<li>NEWATLAS:<a href="https://newatlas.com/tag/autonomous-vehicle/" target="_blank" rel="noopener">https://newatlas.com/tag/autonomous-vehicle/</a></li>
<li>WHARTON:<a href="https://pvmi.wharton.upenn.edu/tag/autonomous-vehicles/" target="_blank" rel="noopener">https://pvmi.wharton.upenn.edu/tag/autonomous-vehicles/</a></li>
<li>Forbes:<a href="https://www.forbes.com/forbesapi/search/all.json?limit=50&amp;orfilters=&amp;query=self+driving+car&amp;retrievedfields=author,authors,blogType,date,description,editorsPick,hashtags,naturalId,trendingHashtags,image,slides,title,type,uri&amp;sort=score&amp;start=&amp;startdate=&amp;withentity=true" target="_blank" rel="noopener">Search api</a></li>
</ul>
<h3 id="HTML内容处理"><a href="#HTML内容处理" class="headerlink" title="HTML内容处理"></a>HTML内容处理</h3><p>抓取部分主要依赖BeautifulSoup，基类主要完成文章内容内容页的抓取，具体的内容页完成具体网站列表页文章列表的提取。比如卫报内容的抓取过程：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment">#! /usr/bin/env python</span></span><br><span class="line"><span class="comment"># coding=utf8</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="keyword">from</span> urllib2 <span class="keyword">import</span> urlopen</span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Scrapy</span>:</span></span><br><span class="line">    <span class="comment"># news content fetch </span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fetchContent</span><span class="params">(self, url)</span>:</span></span><br><span class="line">        soup  = BeautifulSoup(urlopen(url))</span><br><span class="line">        news = <span class="string">''</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># title </span></span><br><span class="line">        title = soup.title.string</span><br><span class="line">        news += soup.title.string + <span class="string">'\r\n\n'</span></span><br><span class="line">        <span class="comment"># content</span></span><br><span class="line">        <span class="keyword">for</span> string <span class="keyword">in</span> soup.find_all(<span class="string">'p'</span>):</span><br><span class="line">            <span class="keyword">if</span> string.string != <span class="keyword">None</span>:</span><br><span class="line">                news+=string.string</span><br><span class="line"></span><br><span class="line">        news += <span class="string">'\r\n\n'</span> + url</span><br><span class="line"></span><br><span class="line">        self.save_file(title, news)</span><br><span class="line">        <span class="keyword">return</span> Scrapy.news</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">save_file</span><span class="params">(self, title, news_content)</span>:</span></span><br><span class="line">        f = open(<span class="string">'news_sample/'</span> + title + <span class="string">'.news'</span>, <span class="string">'w+'</span>)</span><br><span class="line">        f.write(news_content.encode(<span class="string">'utf-8'</span>))</span><br><span class="line">        f.close()</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Guardian</span><span class="params">(Scrapy)</span>:</span></span><br><span class="line">    data_source = <span class="string">"https://www.theguardian.com/technology/self-driving-cars"</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fetchArticleHref</span><span class="params">(self)</span>:</span></span><br><span class="line">        <span class="comment"># url for autonomous vehicles tags</span></span><br><span class="line">        <span class="comment">#soup  = BeautifulSoup(urlopen(Guardian.data_source))</span></span><br><span class="line">        soup = BeautifulSoup(urlopen(<span class="string">"https://www.theguardian.com/technology/self-driving-cars"</span>))</span><br><span class="line">        <span class="comment"># href</span></span><br><span class="line">        scrapy = Scrapy()</span><br><span class="line">        <span class="keyword">for</span> article <span class="keyword">in</span> soup.find_all(<span class="string">'h2'</span>):</span><br><span class="line">            article_url = article.a.get(<span class="string">'href'</span>)</span><br><span class="line">            <span class="keyword">print</span> article_url</span><br><span class="line">            news = scrapy.fetchContent(article_url)</span><br><span class="line">            <span class="keyword">print</span> news</span><br></pre></td></tr></table></figure>
<h2 id="Questions"><a href="#Questions" class="headerlink" title="Questions"></a>Questions</h2><p>刚开始通过BeautifulSoup获取到的HTML内容粒度有些粗，噪声很大，需要将javascript部分的内容也去掉；后来更精准的办法是将标题与文本内容分别获取即可。</p>
<p>处理后的新闻内容，以单独的文件存储。格式为：<br><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">标题</span><br><span class="line"></span><br><span class="line">文章正文</span><br><span class="line">文章链接</span><br></pre></td></tr></table></figure></p>
<p>接下来针对已经抓取到的124文章，做整体的分析。<br><figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> nltk</span><br><span class="line"><span class="keyword">from</span> nltk.tokenize <span class="keyword">import</span> RegexpTokenizer </span><br><span class="line"><span class="keyword">from</span> nltk.corpus <span class="keyword">import</span> stopwords</span><br><span class="line"><span class="keyword">from</span> nltk.book <span class="keyword">import</span> * </span><br><span class="line"></span><br><span class="line">raw = <span class="string">''</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">4</span>):</span><br><span class="line">    f = open(<span class="string">'news_sample/news'</span> + str(i))</span><br><span class="line">    raw += f.read()</span><br><span class="line"></span><br><span class="line">news_files = glob.glob(<span class="string">'news_sample/*.news'</span>)</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> news_files:</span><br><span class="line">        <span class="keyword">with</span> open(i,<span class="string">'rb'</span>) <span class="keyword">as</span> infile:</span><br><span class="line">            raw +=(infile.read())</span><br><span class="line"></span><br><span class="line">tokenizer = RegexpTokenizer(<span class="string">r'\w+'</span>)</span><br><span class="line">token = tokenizer.tokenize(raw.decode(<span class="string">'utf-8'</span>))</span><br><span class="line"></span><br><span class="line">filtered = [word <span class="keyword">for</span> word <span class="keyword">in</span> token <span class="keyword">if</span>(word <span class="keyword">not</span> <span class="keyword">in</span> stopwords.words(<span class="string">'english'</span>))]</span><br><span class="line">fd = FreqDist(filtered)</span><br><span class="line">fd.plot(<span class="number">100</span>, cumulative=<span class="keyword">False</span>)</span><br></pre></td></tr></table></figure></p>
<p>以下为人工未干预的词频分布情况，排名前100：<br><img src="http://7xk16m.com1.z0.glb.clouddn.com/figure_100_for_124_upper.png" width="99%"></p>
<p align="center">查看原图更清晰</p>


<p>之我见：</p>
<ul>
<li><h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2></li>
<li><a href="https://en.wikipedia.org/wiki/Natural_Language_Toolkit" target="_blank" rel="noopener">Natural_Language_Toolkit</a></li>
<li><a href="https://www.jiqizhixin.com/articles/2017-02-16" target="_blank" rel="noopener">理解和实现自然语言处理终极指南</a></li>
<li><a href="https://zh.wikipedia.org/zh-cn/双字母组" target="_blank" rel="noopener">双字母组- 维基百科，自由的百科全书</a></li>
<li><a href="https://zh.wikipedia.org/zh-cn/N元语法" target="_blank" rel="noopener">n元语法- 维基百科，自由的百科全书</a></li>
<li><a href="http://blog.csdn.net/fighting_no1/article/details/51038942" target="_blank" rel="noopener">PDFMiner提取PDF文本</a></li>
</ul>


  
    <div class="comments" id="comments">
      
        <div onclick="showGitment()" id="gitment-display-button">如果你有不同看法？</div>
        <div id="gitment-container" style="display:none"></div>
      
    </div>
  

<div style="display:none">
<script src="http://s4.cnzz.com/stat.php?id=1254090228&web_id=1254090228" language="JavaScript"></script>script>
</div>




    
    
        
        <link rel="stylesheet" href="https://aimingoo.github.io/gitmint/style/default.css">
        <script src="https://aimingoo.github.io/gitmint/dist/gitmint.browser.js"></script>
    

    
      <style>
        a.gitment-editor-footer-tip { display: none; }
        .gitment-container.gitment-footer-container { display: none; }
      </style>
    



      <script type="text/javascript">
      function renderGitment(){
        var gitment = new Gitmint({
            id: window.location.href, 
            owner: 'mickeyouyou',
            repo: 'blog_comment',
            
            lang: "en" || navigator.language || navigator.systemLanguage || navigator.userLanguage,
            
            oauth: {
            
            
                client_secret: '27804beebc0d0aa2ae7271191fd5adac6d1b8cb7',
            
                client_id: '57e78fbfba943c338437'
            }});
        gitment.render('gitment-container');
      }

      
          function showGitment(){
            document.getElementById("gitment-display-button").style.display = "none";
            document.getElementById("gitment-container").style.display = "block";
            renderGitment();
          }
      
      </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
    




</body>
</html>